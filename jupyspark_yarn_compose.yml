# docker-compose -f jupyspark_standalone_compose.yml up --scale spark-worker=2 (-d)
# docker-compose -f jupyspark_standalone_compose.yml down
version: "3.3"
services:
  jupyspark:
  # docker container run -it --rm -e JUPYTER_ENABLE_LAB=yes -p 8888:8888 -v $(pwd)/../../code:/home/jovyan/work 
  # --mount type=tmpfs,destination=/data,tmpfs-mode=1777 --add-host=github.blah.com:11.11.11.11 
  # --name jupyspark dataismus/jupyspark:LOCAL 
    image: dataismus/jupyspark:LOCAL
    build:
      dockerfile: ./Dockerfile
      context: .
    container_name: jupyspark
    ports:
      - 8888:8888
    networks:
      - spark_cluster
    volumes:
      # - /Users/dimitris/work/datasets/:/home/jovyan/data 
      - ./../../code:/home/jovyan/work
    tmpfs:
      - /data:mode=1777,size=1000
    extra_hosts:
      - github.blah.com:11.11.11.11
    command: start-notebook.sh

##################### the Spark cluster nodes #######################
#####################################################################
# spark-submit --master spark://spark-master:7077 --class org.apache.spark.examples.SparkPi $SPARK_HOME/examples/jars/spark-examples_2.11-2.4.0.jar 100

  spark-master:
    image: dataismus/spark_node:latest
    depends_on:
      - jupyspark
    container_name: spark-master
    hostname: spark-master
    ports:
      - 8080:8080
      - 7077:7077
    networks:
      - spark_cluster
    environment:
      - SPARK_MASTER_LOG=/spark/logs
    command: /spark/bin/spark-class org.apache.spark.deploy.master.Master --ip spark-master --port 7077 --webui-port 8080
  spark-worker:
    image: dataismus/spark_node:latest
    depends_on:
      - spark-master
    ports:
      - 8081
    networks:
      - spark_cluster
    environment:
      - SPARK_WORKER_LOG=/spark/logs
    command: /spark/bin/spark-class org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://spark-master:7077


networks:  
  spark_cluster:
    driver: bridge
    ipam:
      driver: default